[참고강의 바로가기](https://www.youtube.com/watch?v=hq4dpyuX4Uw&list=PL52K_8WQO5oUuH06MLOrah4h05TZ4n38l&index=11)

Qucik Sort 역시 Merge sort와 마찬가지로 **분할정복법**을 이용합니다. 

Merge sort와의 차이점은 데이터를 분할하는 방법에 있습니다. 

Merge sort에서는 주어진 데이터를 **절반**으로 쭉 분할하여 각각을 정렬합니다. 

**하지만,** quick sort는 주어진 데이터 중에 하나의 값을 기준 값으로 선택합니다. 

이 값이 바로 **pivot value**입니다. 

Pivot value를 선택하는데에는 여러가지 방법이 있으니 우선은 마지막 값을 선택하기로 하고 설명을 진행합니다. 

### Quick Sort의 개요
- 분할

**pivot 값을 기준으로 pivot 보다 작은 값들과 pivot 보다 큰 값들로 분할**합니다.

때문에, merge sort처럼 반드시 반반으로 쪼개어지는 것은 아닙니다. 

만약 pivot value가 전체 data 중에서 가장 작거나 큰 값이라면 극단적로 쪼개어지겠지요.

물론 pivot value에 따라서 적절하게 균형이 잡힌 분할도 가능합니다. 

- 정복

분할된 **양쪽을 각각 recursion(quick sort)으로 정렬합니다.

- 합병

할 일이 없습니다! 

왜일까요? 

=> 애초에 pivot보다 작은 애와 큰 애로 분할하였기 때문에, 앞쪽에 있는 애들은 모두 뒷쪽에 있는 애들보다 작습니다.

그러니까, 앞쪽과 뒷쪽을 각각 recursion으로 정렬했으니 합병단계 이후에는 data들이 이미 정렬된 상태입니다.

#### pshuedo cod
```
quickSort(A[],p,r)
{
    // basecase : p >= r :: 정렬할 data가 1개이거나 0개 -> 정렬할 것이 없다.
    if(p < r) then {
        q = partition(A,p,r); //pivot의 위치
        quickSort(A,p,q-1);
        quickSort(A,q+1,r);
        }
    }
}
```
```
partition(A[],p,r)
{
    배열 A[p...r]의 원소들을 A[r]을 기준으로 양쪽으로 재배치한다.
    A[r]이 위치한 index를 return
}
```
### Partition을 어떻게 하면 좋을까요?

우리가 할 일은 전체 data 중에서 pivot value를 하나 정하여 이것을 다른 값들과 비교하며 pivot 보다 큰 값, pivot 보다 작은 값으로 분류하는 것입니다.

그렇다면 변하지 않는 pivot값을 이리저리 옮겨다니는 것은 몹시 비효율적인 일입니다.

따라서 이 pivot을 고정시키고 나머지 친구들을 적절히 분할해야합니다.

그런 다음, 마지막 단계로 pivot을 pivot보다 큰 애들 중 맨 첫번째 값과 바꾸어줍니다.

### 어떻게 pivot을 고정시킬까요?

각각의 data들을 pivot과 모두 한번씩 비교하는 수 밖엔는 없습니다.

예를 들어서,  
첫번째 값부터 순서대로 쭉 비교해오면서 p부터 j-1까지의 값은 이미 pivot과 한번씩 다 비교하고 분류를 마쳤다고 가정합니다.  
그럼 이제 j번째 value와 pivot value를 비교할 차례입니다. 

i : pivot보다 작은 값들 중 마지막 값의 index
j : 현재 pivot과 비교할 위치

```
if(A[j] >= A[r] ) -> pass // 이미 분류가 된 상태 ! 
else if(A[j] < A[r])
-> i <- i+1
   A[i]<->A[j]
   j <- j+1
```
Partition의 슈도코드
```
Partition(A,p,r)
{
    x <- A[r]; // pivot
    i <- p-1; // i는 pivot보다 작은 값중 제일 오른쪽 애 
    for j<-p to r-1
        if A[j] <= x then
            i<- i+1;
            A[i]<->A[j]
    A[i+1]<->A[r];
    return i+1;
}
```

### 시간 복잡도 분석
#### Partition 하는데 걸리는 시간은?
n개의 data를 partition하기 위해서는 모든 data들을 pivot과 한번씩 쭉 비교해야합니다.

따라서 O(N)

data를 분할하기 위해서는 반드시 모든 data들을 비교하는 작업을 거쳐야하므로 data 분할에 걸리는 시간은 항상 같습니다. 

### Quick Sort의 최악의 경우 시간 복잡도
#### 최악의 경우 : O(n^2)

Merge sort의 경우 data를 항상 반으로 분할하기 때문에,  
n개의 데이터를 정렬하는 데 걸리는 시간을 T(n)이라고 한다면 merge sort의 시간복잡도는  
T(n) = 2T(n/2) 이라는 점화식을 풀이한 것이었습니다.

그런데 quick sort는 data가 n개 일 때, 어떤 비율로 data가 분할되는지 알 수 없고 그 마저도 pivot vlaue에 따라 달라집니다.

그렇다면 quick sort에서 최악의 경우는 언제일까요?

바로 **이미 정렬된 데이터가 입력으로 들어왔을 때, 마지막 원소를 피봇으로 선택**하는 경우 입니다.

pivot보다 큰 값을 가진 친구가 아무도 없을 때를 생각해봅시다!

#### 최선의 경우 : O(nlogn)
그렇다면 **최선의 경우**는 언제일까요?

아주 아주 운이 좋아 pivot 값이 전체 값 중에서 딱 가운데에 해당될 경우 입니다.

이 경우 시간복잡도는 merge sort와 같아집니다.

### Quick 이라는 이름이 붙은 이유?
Quick sort는 최악의 경우와 최선의 경우 시간복잡도의 편차가 매우 큰 편입니다. 

그렇다면 왜 Quick 이라는 이름이 붙은걸까요?

이 이유는 **평균 시간복잡도**에 있습니다.

#### Balanced Partition
항상 한 쪽이 적어도 1/9이상이 되도록 분할하는 방법을 생각해봅시다.

![사진넣자용]()

Quick sort 알고리즘의 성능은 partition이 얼마나 잘 balance 되어 있는가 에 따라 달라집니다.

#### 평균 시간복잡도
그럼 이제 평균 시간복잡도에 대해 생각해봅시다. 

평균 시간복잡도란, sigma(어떤 사건이 일어날 확률 * 그 사건이 일어났을 때의 시간)

sorting algorithm에서 평균 시간복잡도란,

모든 가능한 입력 I에 대해서 sigma(어떤 입력이 들어올 확률 * 그 입력이 들어왔을 때 정렬하는 데 걸리는 시간)

즉,  
P(I): I가 입력으로 들어올 확률  
T(I): I를 정렬하는 데 걸리는 시간  
=> 평균시간복잡도 A(n) = sigma(P(I)*T(I))

그런데 문제는 P(I)의 값이 정해져 있는 것이 아닙니다. 

그러니까 P(I)가 얼마인지에 대한 토론은 무의미한 것이지요.

대신에 P(I)를 **적절히 modeling**하는 것은 가능합니다. 

입력에 대해 적절한 확률적인 모델을 세우는 것입니다. 

#### 확률적 model 
정렬의 경우에는 입력 데이터를 1~n 사이의 정수라고 가정

1) 1~n 사이의 정수들이 뒤섞여 있는 것이 sorting algorithm의 입력이라고 가정

2) 1~n까지의 정수들을 뒤섞어서 만들 수 있는 순열은 총 n! 가지가 있다.  
   그랬을 때, n!개의 순열 각각이 입력으로 들어올 확률은 일정하다.  
    => P(I) = 1/(n!)  
![49.30'' 평균시간복잡도 분석 사진]()

### Pivot을 선택하는 방법
Quick sort 알고리즘의 성능을 좌지우지(?)하는 pivot value의 선택 방법에는 어떤 것들이 있을까요?

#### 첫번째 또는 마지막 값 
첫번째 값을 pivot value로 선택하는 것이 가장 **비효율**적입니다.

왜냐하면, 현실에서 다룰 data들은 random 하지 않고 앞단계를 거치면서 거꾸로 sorting 되어 있을 확률이 높기 때문입니다. 

#### 첫번째, 마지막 그리고 가운데 값 중 중간값 
최악의 시간복잡도(O(n^2))는 달라지지 않습니다.

#### random 하게 선택
특정한 위치나 규칙으로 pivot value를 선택하는 것이 아니라, **n개의 data 중에서 random으로 선택**하는 것입니다.

`최악의 입력`이라는 개념이 없습니다.

어떤 입력이 들어오더라도 그 중에 누가 pivot이 될지가 이미 정해진게 아니기 때문입니다.

이 때, 최악의 경우는 항상 전체 중 최소값을 선택하게 될 때 입니다.  
`no worst case instance, but worst case execution`
:: 평균시간복잡도 (nlogn)
